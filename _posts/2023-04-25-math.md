---
layout: post
title: Normalizing Flow (tmp)
date: 2023-04-25 11:12:00-0400
description: an explanation for normalizing flow
tags: generative_model math
categories: sample-posts
related_posts: false
---

원 논문 : Variational Inference with Normalizing Flows, 2015

일반적으로 variational inference에서 posterior distribution로 간단한 family의 distribution을 사용한다. 이 논문의 목적은 variational inference를 위해 rich posterior approximation을 구축하는 방법을 찾는 것이다. 저자는 normalizing flow라는 방법을 제안하는데, 이는 간단한 확률밀도를 갖는 분포에서 출발하여 복잡한 분포를 표현할 수 있을 때까지 invertible transformation을 순차적으로 적용한다. Normalizing flow라는 방법이 어떻게 복잡한 posterior를 표현할 수 있게 되는지 알아보자.

# Variational Inference
Variational inference framework에서는 lower bound를 최대화하는 방식으로 likelihood를 최대화한다.
\begin{equation}
\log p_\theta(\mathbf{x})\geq -D_{KL}
\end{equation}


This theme supports rendering beautiful math in inline and display modes using [MathJax 3](https://www.mathjax.org/) engine. You just need to surround your math expression with `$$`, like `$$ E = mc^2 $$`. If you leave it inside a paragraph, it will produce an inline expression, just like $$ E = mc^2 $$.

To use display mode, again surround your expression with `$$` and place it as a separate paragraph. Here is an example:

$$
\sum_{k=1}^\infty |\langle x, e_k \rangle|^2 \leq \|x\|^2
$$

You can also use `\begin{equation}...\end{equation}` instead of `$$` for display mode math.
MathJax will automatically number equations:

\begin{equation}
\label{eq:cauchy-schwarz}
\left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right)
\end{equation}

and by adding `\label{...}` inside the equation environment, we can now refer to the equation using `\eqref`.

Note that MathJax 3 is [a major re-write of MathJax](https://docs.mathjax.org/en/latest/upgrading/whats-new-3.0.html) that brought a significant improvement to the loading and rendering speed, which is now [on par with KaTeX](http://www.intmath.com/cg5/katex-mathjax-comparison.php).
